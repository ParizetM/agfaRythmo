# ğŸ¯ AmÃ©lioration Clustering Diarization - Version 2.0

**Date** : 31 janvier 2025  
**Objectif** : AmÃ©liorer la prÃ©cision de dÃ©tection des locuteurs en utilisant une approche "embeddings-like"

---

## ğŸ”´ ProblÃ¨me Initial

**SymptÃ´mes** :
- âŒ MÃªme personne â†’ Plusieurs speakers diffÃ©rents
- âŒ Personnes diffÃ©rentes â†’ MÃªme speaker
- âŒ RÃ©sultats complÃ¨tement incohÃ©rents

**Cause identifiÃ©e** :
Les 112 dimensions de features (MFCC, pitch, spectral, chroma, formants) capturent des **propriÃ©tÃ©s acoustiques** mais pas l'**identitÃ© vocale**.

La distance euclidienne sur ces features brutes ne fonctionne pas car :
- Elle compare les magnitudes (amplitude) au lieu de l'identitÃ©
- Les features ne sont pas "normalisÃ©es" comme des embeddings
- DiffÃ©rentes dimensions ont des Ã©chelles trÃ¨s diffÃ©rentes

---

## âœ… Solution ImplÃ©mentÃ©e

### 1ï¸âƒ£ **Normalisation L2 des Features**

**Avant** :
```python
features_array = np.array([...])  # 112D raw features
clustering = AgglomerativeClustering(metric='euclidean', linkage='ward')
labels = clustering.fit_predict(features_array)
```

**AprÃ¨s** :
```python
from sklearn.preprocessing import normalize
features_normalized = normalize(features_array, norm='l2')  # Vecteurs unitaires
```

**Effet** :
- Convertit chaque vecteur 112D en **vecteur unitaire** (longueur = 1)
- Comme les embeddings de speaker recognition professionnels
- Focus sur la **direction** (identitÃ©) au lieu de la magnitude (volume)

---

### 2ï¸âƒ£ **Distance Cosine au lieu d'Euclidienne**

**Avant** :
```python
metric='euclidean'  # Distance dans l'espace, sensible Ã  l'amplitude
linkage='ward'      # Minimise variance intra-cluster
```

**AprÃ¨s** :
```python
metric='cosine'     # Mesure l'angle entre vecteurs (similaritÃ© d'identitÃ©)
linkage='average'   # Compatible avec cosine
```

**Effet** :
- Distance cosine = 1 - cosine_similarity
- Mesure l'**angle** entre vecteurs au lieu de la distance euclidienne
- Insensible Ã  l'Ã©chelle (volume, amplitude)
- Parfait pour comparer identitÃ©s vocales

---

### 3ï¸âƒ£ **Approche Hybride avec Fallback**

**Algorithme** :
1. **Essai COSINE** (mÃ©thode principale) :
   - Sur features normalisÃ©es (L2)
   - Teste k=2 Ã  k=min(max_speakers, 8)
   - Silhouette score avec metric='cosine'
   - Validation : minimum 2 segments par cluster

2. **Fallback EUCLIDEAN** (si score cosine < 0.35) :
   - Sur features brutes
   - MÃªme process de sÃ©lection
   - Garde le meilleur des deux

**Code** :
```python
# Approche 1 : Cosine sur features normalisÃ©es
for n_clusters in range(2, min(max_speakers + 1, 9)):
    clustering = AgglomerativeClustering(
        n_clusters=n_clusters,
        metric='cosine',
        linkage='average'
    )
    labels = clustering.fit_predict(features_normalized)
    
    # Validation : min 2 segments/cluster
    unique, counts = np.unique(labels, return_counts=True)
    if np.any(counts < 2):
        continue
    
    score = silhouette_score(features_normalized, labels, metric='cosine')
    # Garde le meilleur score

# Approche 2 : Euclidean fallback si score cosine faible
if best_score < 0.35:
    # MÃªme process avec euclidean...
```

---

## ğŸ“Š Logs AmÃ©liorÃ©s

**Nouveaux messages** :
```
ğŸ”§ Features normalisÃ©es (L2) : (25, 112)

ğŸ§ª Test clustering (2 Ã  8 clusters)...
  ğŸ“ MÃ©thode COSINE (sur features normalisÃ©es):
    k=2: silhouette=0.542, distribution={0: 12, 1: 13}
    k=3: silhouette=0.489, distribution={0: 8, 1: 9, 2: 8}
    k=4: silhouette=0.621, distribution={0: 6, 1: 7, 2: 6, 3: 6}
    
âœ… Meilleur: 4 clusters (silhouette=0.621, mÃ©thode=cosine)
  Cluster 0: 6 segments, Baryton, pitch_moy=125.3Hz
  Cluster 1: 7 segments, Soprano, pitch_moy=245.7Hz
  Cluster 2: 6 segments, Tenor, pitch_moy=165.2Hz
  Cluster 3: 6 segments, Alto, pitch_moy=195.4Hz
```

**Informations affichÃ©es** :
- âœ… MÃ©thode utilisÃ©e (cosine ou euclidean)
- âœ… Distribution des segments par cluster
- âœ… Silhouette score pour chaque k testÃ©
- âœ… DÃ©tails par cluster (tessiture, pitch moyen)

---

## ğŸ§ª Comment Tester

### Option 1 : Script de Test Automatique

```bash
cd /Users/martinp/Documents/GitHub/agfaRythmo
./test_new_clustering.sh
```

**Ce qu'il fait** :
1. Prend une vidÃ©o de test
2. Extrait l'audio (WAV 16kHz mono)
3. Transcription Whisper (modÃ¨le tiny)
4. Lance diarization avec nouveau clustering
5. Affiche les speakers dÃ©tectÃ©s et leur distribution

### Option 2 : Test Manuel

```bash
cd agfa-rythmo-backend

# 1. Extraire audio
ffmpeg -i storage/app/private/public/videos/VOTRE_VIDEO.mp4 \
    -ar 16000 -ac 1 /tmp/audio.wav

# 2. Whisper
whisper /tmp/audio.wav --model tiny --language fr \
    --output_format json --output_dir /tmp

# 3. Diarization (nouveau clustering)
python3 scripts/simple_diarization.py \
    /tmp/audio.wav \
    /tmp/audio.json \
    /tmp/diarization.json \
    --max-speakers 10

# 4. Analyser rÃ©sultat
cat /tmp/diarization.json | jq '.segments[] | {speaker, text}'
```

---

## ğŸ“ˆ AmÃ©lioration Attendue

### Avant (Euclidean brut)
- 4 personnes â†’ DÃ©tection : 2 speakers (sous-dÃ©tection)
- MÃªme personne â†’ 3 speakers diffÃ©rents (sur-segmentation)
- **Score utilisateur** : "nul a chier" âŒ

### AprÃ¨s (L2 + Cosine)
- 4 personnes â†’ DÃ©tection : 4 speakers âœ…
- MÃªme personne â†’ 1 speaker cohÃ©rent âœ…
- **Score attendu** : PrÃ©cision significativement amÃ©liorÃ©e ğŸ¯

**Pourquoi** :
- Normalisation L2 â†’ Features deviennent des "embeddings" unitaires
- Distance cosine â†’ Compare identitÃ© vocale, pas amplitude
- Validation clusters â†’ Ã‰vite sur-segmentation
- Fallback euclidean â†’ Robustesse si cosine Ã©choue

---

## ğŸ”¬ ThÃ©orie : Embeddings vs Features Brutes

### Features Brutes (ancien)
```
Personne A : [12.3, -5.6, 8.2, ..., 145.7]  (volume fort)
Personne A : [6.1, -2.8, 4.1, ..., 72.8]   (volume faible)
Distance euclidienne = GRANDE (diffÃ©rentes magnitudes)
â†’ ClassÃ©es comme 2 personnes diffÃ©rentes âŒ
```

### Embeddings NormalisÃ©s (nouveau)
```
Personne A : [0.34, -0.15, 0.23, ..., 0.41]  (normalisÃ©)
Personne A : [0.34, -0.15, 0.23, ..., 0.41]  (normalisÃ©)
Distance cosine = PETITE (mÃªme direction)
â†’ ClassÃ©es comme mÃªme personne âœ…
```

**Analogie** :
- Features brutes = position GPS (lat, lon, altitude)
- Embeddings = direction boussole (angle seulement)
- Pour identifier une personne, on veut sa "direction vocale", pas son volume

---

## ğŸš€ Prochaines Ã‰tapes

### Si Ã§a marche (score > 0.8)
1. âœ… Valider avec plusieurs vidÃ©os de test
2. âœ… Supprimer anciens logs debug
3. âœ… Documenter dans instructions_projets.md
4. âœ… Merger dans main

### Si amÃ©lioration mais pas parfait (score 0.5-0.7)
1. ğŸ”§ Augmenter features (200D au lieu de 112D)
2. ğŸ”§ Ajouter features prosodiques (intonation, rythme)
3. ğŸ”§ Essayer combinaison cosine + euclidean pondÃ©rÃ©e

### Si toujours cassÃ© (score < 0.5)
1. ğŸ” Envisager modÃ¨le prÃ©-entraÃ®nÃ© lÃ©ger :
   - **Resemblyzer** : 256D embeddings, ~20MB
   - **SpeechBrain** : xvectors, ~50MB
   - Trade-off : +30MB RAM mais vraie qualitÃ© embeddings
2. ğŸ” Ou : UI semi-supervisÃ©e (user clique quelques segments par speaker)

---

## ğŸ“ Fichiers ModifiÃ©s

- `agfa-rythmo-backend/scripts/simple_diarization.py` :
  - Fonction `apply_clustering()` complÃ¨tement refactorisÃ©e
  - Ajout normalisation L2
  - Ajout distance cosine
  - Approche hybride cosine + euclidean
  - Logs dÃ©taillÃ©s

- `test_new_clustering.sh` (nouveau) :
  - Script de test automatique complet

- `CHANGELOG_CLUSTERING_V2.md` (ce fichier) :
  - Documentation changements

---

## ğŸ“ Ressources

**Distance Cosine** :
- [Cosine Similarity - Wikipedia](https://en.wikipedia.org/wiki/Cosine_similarity)
- Formule : `cosine_similarity = dot(A, B) / (||A|| * ||B||)`
- Distance : `1 - cosine_similarity`

**Speaker Embeddings** :
- [X-vectors for Speaker Recognition](https://www.danielpovey.com/files/2018_icassp_xvectors.pdf)
- [Resemblyzer](https://github.com/resemble-ai/Resemblyzer)
- IdÃ©e : Deep learning â†’ embeddings discriminatifs

**L2 Normalization** :
- Convertit vecteur en vecteur unitaire (longueur = 1)
- Formule : `v_normalized = v / ||v||`
- Effet : Distance euclidienne â‰ˆ Distance cosine (pour vecteurs unitaires)

---

**Auteur** : GitHub Copilot + Martin P.  
**Version** : 2.0 (Clustering avec embeddings-like features)  
**Status** : ğŸ§ª En test

---

## âœ¨ TL;DR

**Changement** : Features 112D â†’ NormalisÃ©es L2 â†’ Distance Cosine au lieu d'Euclidienne

**Pourquoi** : Traiter features comme des "embeddings" vocaux (direction) au lieu de mesures acoustiques brutes (magnitude)

**RÃ©sultat attendu** : MÃªme personne = mÃªme speaker, Personnes diffÃ©rentes = speakers diffÃ©rents

**Comment tester** : `./test_new_clustering.sh`
