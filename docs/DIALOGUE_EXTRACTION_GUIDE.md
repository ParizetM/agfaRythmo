# Guide d'extraction automatique des dialogues

**Version** : 2.2.0-beta | **Date** : 31 octobre 2025

## üìã Vue d'ensemble

L'extraction automatique de dialogues utilise l'intelligence artificielle pour transcrire automatiquement les paroles d'une vid√©o et cr√©er les timecodes avec d√©tection des locuteurs.

### Fonctionnalit√©s

- ‚úÖ **Transcription automatique** : Extraction de tous les dialogues de la vid√©o
- ‚úÖ **D√©tection des locuteurs** : Identification automatique des diff√©rents speakers (diarization)
- ‚úÖ **Multi-langue** : Support de 12 langues (fran√ßais, anglais, chinois, japonais, etc.)
- ‚úÖ **Cr√©ation automatique** : Timecodes et personnages g√©n√©r√©s automatiquement
- ‚úÖ **Optimis√© 2GB RAM** : Utilise des mod√®les l√©gers (Whisper tiny/base/small)
- ‚úÖ **Traitement local** : Aucune donn√©e envoy√©e √† des services externes
- ‚úÖ **Progression temps r√©el** : Suivi d√©taill√© de l'extraction en cours
- ‚úÖ **Cancellation** : Possibilit√© d'annuler √† tout moment

---

## üîß Installation

### Pr√©requis

- **Python 3.8+** install√© sur le serveur
- **FFmpeg** pour extraction audio
- **2GB RAM minimum** recommand√©
- **Espace disque** : ~500MB pour les mod√®les Whisper

### Installation des d√©pendances Python

```bash
cd agfa-rythmo-backend
pip install -r scripts/requirements.txt
```

**Contenu de `scripts/requirements.txt`** :
```
openai-whisper==20231117
pyannote-audio==3.1.1
```

### Configuration `.env`

Ajouter dans `agfa-rythmo-backend/.env` :

```bash
# ======== Extraction de dialogues IA ========
AI_DIALOGUE_EXTRACTION_ENABLED=true

# Mod√®le Whisper (tiny/base/small - tiny recommand√© pour 2GB RAM)
WHISPER_MODEL=tiny

# Diarization (d√©tection locuteurs)
DIARIZATION_ENABLED=true
MAX_SPEAKERS=10

# Langues support√©es (fr,en,zh,ja,es,de,it,pt,ru,ko,ar,hi)
SUPPORTED_LANGUAGES=fr,en,zh,ja,es,de,it,pt,ru,ko,ar,hi
```

### V√©rification de l'installation

```bash
# Tester FFmpeg
ffmpeg -version

# Tester Python et les d√©pendances
python3 agfa-rythmo-backend/scripts/extract_dialogues.py --help
```

---

## üéØ Utilisation

### 1. Depuis l'interface (recommand√©)

1. **Ouvrir un projet** sans timecodes existants
2. **Cliquer sur le bouton "IA"** (ic√¥ne √©toile, gradient violet/rose)
3. **S√©lectionner "Extraction de dialogues"** dans le menu IA
4. **Configurer les param√®tres** :
   - **Langue** : Choisir la langue parl√©e dans la vid√©o
   - **Max speakers** : Nombre maximum de locuteurs √† d√©tecter (2-20)
   - **Mod√®le Whisper** : 
     - `tiny` : Rapide, l√©ger (2GB RAM OK)
     - `base` : Plus pr√©cis, 4GB RAM
     - `small` : Meilleure qualit√©, 8GB RAM
5. **Lancer l'extraction**
6. **Suivre la progression** (4 √©tapes) :
   - Extraction audio (0-20%)
   - Transcription Whisper (20-70%)
   - D√©tection locuteurs (70-90%)
   - Cr√©ation timecodes (90-100%)
7. **R√©sultat** : Timecodes et personnages cr√©√©s automatiquement !

### 2. Via API (avanc√©)

**D√©marrer l'extraction** :
```bash
POST /api/projects/{project_id}/dialogue-extraction/start
Content-Type: application/json

{
  "language": "fr",
  "max_speakers": 5,
  "whisper_model": "tiny"
}
```

**V√©rifier le statut** :
```bash
GET /api/projects/{project_id}/dialogue-extraction/status
```

**Annuler l'extraction** :
```bash
POST /api/projects/{project_id}/dialogue-extraction/cancel
```

---

## ‚öôÔ∏è Configuration avanc√©e

### Mod√®les Whisper

| Mod√®le | RAM n√©cessaire | Vitesse | Pr√©cision | Recommand√© pour |
|--------|---------------|---------|-----------|-----------------|
| `tiny` | 1GB | Tr√®s rapide | Bonne | Serveurs limit√©s, tests |
| `base` | 2GB | Rapide | Tr√®s bonne | Usage g√©n√©ral |
| `small` | 4GB | Moyen | Excellente | Haute qualit√© |

### Langues support√©es

- **Fran√ßais** : `fr`
- **Anglais** : `en`
- **Chinois** : `zh`
- **Japonais** : `ja`
- **Espagnol** : `es`
- **Allemand** : `de`
- **Italien** : `it`
- **Portugais** : `pt`
- **Russe** : `ru`
- **Cor√©en** : `ko`
- **Arabe** : `ar`
- **Hindi** : `hi`

### Diarization (d√©tection des locuteurs)

**Activer/D√©sactiver** :
```bash
DIARIZATION_ENABLED=true  # D√©tection automatique des speakers
DIARIZATION_ENABLED=false # Un seul speaker pour tous les dialogues
```

**Nombre maximum de speakers** :
```bash
MAX_SPEAKERS=10  # Max 10 locuteurs diff√©rents
```

---

## üé® Cr√©ation automatique des personnages

### Palette de couleurs

Les personnages sont cr√©√©s automatiquement avec des couleurs distinctives :

| Speaker | Couleur fond | Couleur texte |
|---------|-------------|---------------|
| Speaker 1 | `#3b82f6` (Bleu) | `#ffffff` |
| Speaker 2 | `#ef4444` (Rouge) | `#ffffff` |
| Speaker 3 | `#10b981` (Vert) | `#ffffff` |
| Speaker 4 | `#f59e0b` (Orange) | `#ffffff` |
| Speaker 5 | `#8b5cf6` (Violet) | `#ffffff` |
| Speaker 6 | `#ec4899` (Rose) | `#ffffff` |
| Speaker 7 | `#14b8a6` (Teal) | `#ffffff` |
| Speaker 8 | `#f97316` (Orange vif) | `#ffffff` |
| Speaker 9 | `#6366f1` (Indigo) | `#ffffff` |
| Speaker 10+ | `#64748b` (Gris) | `#ffffff` |

### Distribution sur les lignes rythmo

Si le projet a **plusieurs lignes rythmo** (ex: 3 lignes) et **plusieurs speakers** (ex: 5 speakers) :
- Les speakers sont **distribu√©s** sur les diff√©rentes lignes
- Exemple avec 3 lignes et 5 speakers :
  - Ligne 1 : Speaker 1, Speaker 4
  - Ligne 2 : Speaker 2, Speaker 5
  - Ligne 3 : Speaker 3

---

## üö® Limitations et contraintes

### Fonctionnement

- ‚ö†Ô∏è **Pas de timecodes existants** : L'extraction est d√©sactiv√©e si le projet a d√©j√† des timecodes
- ‚ö†Ô∏è **Traitement asynchrone** : L'extraction peut prendre **plusieurs minutes** selon la dur√©e de la vid√©o
- ‚ö†Ô∏è **M√©moire** : Respecter les recommandations RAM pour chaque mod√®le Whisper
- ‚ö†Ô∏è **Qualit√© audio** : Les r√©sultats d√©pendent de la qualit√© audio de la vid√©o

### Performances

**Temps d'extraction estim√©** (vid√©o de 10 minutes) :

| Mod√®le | Temps | RAM |
|--------|-------|-----|
| `tiny` | 2-3 min | 1GB |
| `base` | 4-5 min | 2GB |
| `small` | 8-10 min | 4GB |

### Gestion des erreurs

En cas d'√©chec :
- ‚ùå **Rollback automatique** : Tous les timecodes/personnages cr√©√©s sont supprim√©s
- ‚ùå **Fallback speaker unique** : Si la diarization √©choue, un seul speaker est utilis√©
- ‚ùå **Messages d'erreur clairs** : Affich√©s dans l'interface

---

## üîç Troubleshooting

### Probl√®me : "FFmpeg not found"

**Solution** :
```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt install ffmpeg

# CentOS/RHEL
sudo yum install ffmpeg
```

### Probl√®me : "Out of memory"

**Solutions** :
1. Utiliser un mod√®le plus l√©ger : `WHISPER_MODEL=tiny`
2. R√©duire le nombre de speakers : `MAX_SPEAKERS=5`
3. Augmenter la RAM du serveur (minimum 2GB recommand√©)

### Probl√®me : "Extraction √©choue imm√©diatement"

**V√©rifications** :
1. V√©rifier que Python 3.8+ est install√© : `python3 --version`
2. V√©rifier les d√©pendances : `pip list | grep whisper`
3. V√©rifier les logs Laravel : `php artisan pail`
4. V√©rifier le fichier vid√©o existe : `storage/app/videos/`

### Probl√®me : "Diarization ne fonctionne pas"

**Solutions** :
1. V√©rifier `DIARIZATION_ENABLED=true` dans `.env`
2. Installer pyannote-audio : `pip install pyannote-audio==3.1.1`
3. Si probl√®me persiste, d√©sactiver : `DIARIZATION_ENABLED=false`

### Probl√®me : "Mauvaise d√©tection de langue"

**Solutions** :
1. Forcer la langue dans l'interface (ne pas utiliser "auto")
2. V√©rifier la qualit√© audio de la vid√©o
3. Utiliser un mod√®le plus gros : `WHISPER_MODEL=base` ou `small`

---

## üìä Architecture technique

### Pipeline de traitement

```
1. Extraction audio (FFmpeg)
   ‚îú‚îÄ Conversion vid√©o ‚Üí WAV
   ‚îú‚îÄ 16kHz mono
   ‚îî‚îÄ Stockage temporaire

2. Transcription (Whisper)
   ‚îú‚îÄ Chargement mod√®le (tiny/base/small)
   ‚îú‚îÄ D√©tection automatique langue (ou forc√©e)
   ‚îú‚îÄ Segmentation par phrases
   ‚îî‚îÄ Timecodes pr√©cis (start/end)

3. Diarization (pyannote-audio) [optionnel]
   ‚îú‚îÄ Analyse des voix
   ‚îú‚îÄ Identification des locuteurs
   ‚îî‚îÄ Attribution speaker par segment

4. Cr√©ation timecodes + personnages
   ‚îú‚îÄ Insertion en base de donn√©es
   ‚îú‚îÄ Association timecode ‚Üî character
   ‚îú‚îÄ Distribution sur lignes rythmo
   ‚îî‚îÄ Palette couleurs automatique
```

### Job Laravel

**Fichier** : `app/Jobs/ExtractDialogues.php`

**Fonctionnalit√©s** :
- Appelle le script Python avec `proc_open()`
- Mise √† jour de la progression en temps r√©el
- V√©rification cancellation toutes les 2 secondes
- Rollback automatique en cas d'erreur
- Timeout de 30 minutes

### Script Python

**Fichier** : `scripts/extract_dialogues.py`

**Arguments** :
```bash
python3 extract_dialogues.py \
  --video "/path/to/video.mp4" \
  --language "fr" \
  --model "tiny" \
  --max-speakers 5 \
  --output "/path/to/output.json" \
  --project-id 123
```

**Output JSON** :
```json
{
  "timecodes": [
    {
      "start": 1.23,
      "end": 3.45,
      "text": "Bonjour, comment allez-vous ?",
      "speaker": "SPEAKER_00",
      "language": "fr"
    }
  ],
  "speakers": ["SPEAKER_00", "SPEAKER_01"],
  "metadata": {
    "duration": 120.5,
    "model": "tiny",
    "language": "fr"
  }
}
```

---

## üé¨ Workflow complet

### Exemple : Projet de doublage fran√ßais

1. **Cr√©er un projet** avec vid√©o et 3 lignes rythmo
2. **Lancer l'extraction** :
   - Langue : Fran√ßais
   - Max speakers : 5
   - Mod√®le : tiny
3. **Attendre** (progression en temps r√©el)
4. **R√©sultat** :
   - 50 timecodes cr√©√©s automatiquement
   - 3 personnages d√©tect√©s (Speaker 1, 2, 3)
   - Distribution :
     - Ligne 1 : Speaker 1
     - Ligne 2 : Speaker 2
     - Ligne 3 : Speaker 3
5. **R√©vision manuelle** :
   - Renommer "Speaker 1" ‚Üí "Alice"
   - Renommer "Speaker 2" ‚Üí "Bob"
   - Corriger textes si n√©cessaire
6. **Export** : Projet pr√™t pour le doublage !

---

## üîê S√©curit√© et confidentialit√©

### Traitement local

- ‚úÖ **Aucune API externe** : Tout le traitement est fait localement
- ‚úÖ **Donn√©es priv√©es** : Les vid√©os ne quittent jamais le serveur
- ‚úÖ **Mod√®les open-source** : Whisper (OpenAI) et pyannote-audio

### Permissions

- üîí N√©cessite **permission "edit"** ou "admin" sur le projet
- üîí V√©rifie que le projet n'a **pas de timecodes existants**
- üîí Validation des param√®tres c√¥t√© backend (language, max_speakers, model)

---

## üöÄ Am√©liorations futures (Phase 2)

### Traduction automatique

- Transcription dans langue source (ex: anglais)
- Traduction vers langue cible (ex: fran√ßais)
- Contexte bas√© sur sc√®ne/personnages
- UI pour activer/d√©sactiver + s√©lection langue cible

### Validation post-extraction

- Interface de r√©vision des timecodes
- Fusion de speakers mal identifi√©s
- Correction texte en masse
- R√©assignation personnages

### Optimisations

- Support GPU (CUDA) pour acc√©l√©rer Whisper
- Mod√®les Whisper quantifi√©s (plus l√©gers)
- Cache des mod√®les entre extractions
- Parall√©lisation de la diarization

---

## üìù Changelog

### v2.2.0-beta (31 octobre 2025)

- ‚úÖ Extraction automatique dialogues
- ‚úÖ D√©tection locuteurs (diarization)
- ‚úÖ Support 12 langues
- ‚úÖ Cr√©ation auto timecodes + personnages
- ‚úÖ UI compl√®te avec progression temps r√©el
- ‚úÖ Optimis√© 2GB RAM

---

## üí° Conseils et bonnes pratiques

### Pour une meilleure qualit√©

1. **Qualit√© audio** : Utiliser des vid√©os avec audio clair
2. **Langue forc√©e** : Ne pas utiliser "auto" si possible
3. **Mod√®le adapt√©** : `tiny` pour tests, `base` pour production
4. **Speakers r√©aliste** : Ne pas surestimer le nombre de locuteurs
5. **R√©vision manuelle** : Toujours v√©rifier les r√©sultats apr√®s extraction

### Optimisation des performances

1. **Queue workers** : Configurer plusieurs workers Laravel pour traiter en parall√®le
2. **RAM** : Allouer au moins 2GB pour `base` model
3. **CPU** : Pr√©f√©rer multi-core pour diarization
4. **Stockage** : Pr√©voir espace pour fichiers audio temporaires

---

## üìû Support

**Probl√®me** ? Consultez :
1. Les logs Laravel : `php artisan pail`
2. Les logs Python : affich√©s dans l'interface de progression
3. La documentation Whisper : https://github.com/openai/whisper
4. La documentation pyannote : https://github.com/pyannote/pyannote-audio

**Besoin d'aide** ? Ouvrir une issue GitHub avec :
- Version PHP, Python, FFmpeg
- Configuration `.env` (sans secrets)
- Logs complets de l'erreur
- Caract√©ristiques de la vid√©o (dur√©e, format, codec)

---

**Derni√®re mise √† jour** : 31 octobre 2025  
**Maintainer** : Martin P. (@ParizetM)
