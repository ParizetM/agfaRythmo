# Guide d'Utilisation NLLB-200 pour Traduction

**Version** : 1.0.0 | **Date** : 31 octobre 2025

## üìã Vue d'ensemble

NLLB-200 (No Language Left Behind) est un mod√®le de traduction d√©velopp√© par Meta AI qui supporte **200 langues**. Cette int√©gration permet d'utiliser ce mod√®le localement et gratuitement pour traduire les dialogues de vos projets.

### ‚ú® Avantages

- ‚úÖ **Gratuit** : Aucun co√ªt, aucune API key requise
- ‚úÖ **Local** : Traitement sur votre serveur, confidentialit√© totale
- ‚úÖ **200 langues** : Incluant chinois, japonais, cor√©en, arabe, hindi, etc.
- ‚úÖ **Support source** : Toutes les langues support√©es comme SOURCE (contrairement √† DeepL)
- ‚úÖ **Batch natif** : Traduction de plusieurs textes en une seule passe
- ‚úÖ **Qualit√© ‚≠ê‚≠ê‚≠ê‚≠ê** : Excellente qualit√©, particuli√®rement pour langues asiatiques

### ‚ö†Ô∏è Limitations

- Taille : ~2GB pour le mod√®le 600M (t√©l√©chargement √† la premi√®re utilisation)
- Startup : ~3-5 secondes de chargement du mod√®le √† chaque traduction
- Performance : Plus lent que les API cloud (DeepL, Google) mais acceptable en background
- RAM : N√©cessite ~2GB de RAM disponible

## üõ†Ô∏è Installation

### 1. D√©pendances Python

Les d√©pendances sont d√©j√† install√©es si vous avez configur√© l'extraction de dialogues. Sinon :

```bash
cd agfa-rythmo-backend
pip3 install -r scripts/requirements.txt
```

Packages requis :
- `transformers>=4.30.0` : Hugging Face Transformers
- `sentencepiece>=0.1.99` : Tokenizer pour NLLB
- `protobuf>=3.20.0` : S√©rialisation
- `torch>=2.0.0` : PyTorch (d√©j√† install√©)

### 2. Configuration

Modifier `.env` :

```bash
# Activer la traduction
AI_TRANSLATION_ENABLED=true

# Choisir NLLB comme provider
AI_TRANSLATION_PROVIDER=nllb

# Taille du mod√®le (optionnel, d√©faut: 600M)
# Options : 600M (recommand√©), 1.3B, 3.3B
AI_NLLB_MODEL_SIZE=600M
```

### 3. Rechargement configuration

```bash
php artisan config:cache
php artisan queue:restart
```

## üìñ Utilisation

### Via l'interface web

1. Ouvrir un projet avec des timecodes
2. Cliquer sur le bouton **"IA"** (gradient violet/rose)
3. S√©lectionner **"Traduction automatique"**
4. Configurer :
   - **Langue source** : Auto-d√©tection ou s√©lection manuelle
   - **Langue cible** : Langue de destination
   - **Contexte personnages** : Cocher pour am√©liorer la qualit√©
5. Cliquer sur **"Lancer la traduction"**
6. La modal affiche **"NLLB-200"** comme provider avec ‚≠ê‚≠ê‚≠ê‚≠ê
7. Suivre la progression en temps r√©el

### Via la ligne de commande

#### Test simple

```bash
cd agfa-rythmo-backend

# Traduction chinois ‚Üí fran√ßais
python3 scripts/translate_nllb.py \
  --source zh \
  --target fr \
  --text "‰Ω†Â•ΩÔºå‰∏ñÁïå" \
  --model-size 600M
```

Sortie :
```json
{
  "success": true,
  "translation": "Bonjour, le monde",
  "source_lang": "zh",
  "target_lang": "fr"
}
```

#### Traduction batch

Cr√©er `texts.json` :
```json
["‰Ω†Â•Ω", "Ë∞¢Ë∞¢", "ÂÜçËßÅ"]
```

Ex√©cuter :
```bash
python3 scripts/translate_nllb.py \
  --source zh \
  --target fr \
  --batch-file texts.json \
  --output results.json \
  --model-size 600M
```

R√©sultat dans `results.json` :
```json
{
  "success": true,
  "translations": ["Bonjour", "Merci", "Au revoir"],
  "source_lang": "zh",
  "target_lang": "fr"
}
```

### Via le service Laravel

```php
use App\Services\TranslationService;

$service = new TranslationService('nllb');

// Traduction simple
$result = $service->translate('‰Ω†Â•Ω', 'fr', 'zh');
// => "Bonjour"

// Traduction batch
$texts = ['‰Ω†Â•Ω', 'Ë∞¢Ë∞¢', 'ÂÜçËßÅ'];
$results = $service->translateBatch($texts, 'fr', 'zh');
// => ["Bonjour", "Merci", "Au revoir"]
```

## üåç Langues support√©es

NLLB-200 supporte 200 langues avec codes FLORES-200. Le syst√®me convertit automatiquement les codes ISO standards.

### Principales langues (25 configur√©es)

| Code ISO | Langue | Code FLORES-200 |
|----------|--------|-----------------|
| `en` | Anglais | `eng_Latn` |
| `fr` | Fran√ßais | `fra_Latn` |
| `zh` | Chinois | `zho_Hans` |
| `ja` | Japonais | `jpn_Jpan` |
| `ko` | Cor√©en | `kor_Hang` |
| `es` | Espagnol | `spa_Latn` |
| `de` | Allemand | `deu_Latn` |
| `it` | Italien | `ita_Latn` |
| `pt` | Portugais | `por_Latn` |
| `ru` | Russe | `rus_Cyrl` |
| `ar` | Arabe | `arb_Arab` |
| `hi` | Hindi | `hin_Deva` |
| `tr` | Turc | `tur_Latn` |
| `id` | Indon√©sien | `ind_Latn` |
| `vi` | Vietnamien | `vie_Latn` |
| `th` | Tha√Ø | `tha_Thai` |
| `nl` | N√©erlandais | `nld_Latn` |
| `pl` | Polonais | `pol_Latn` |
| `uk` | Ukrainien | `ukr_Cyrl` |
| `cs` | Tch√®que | `ces_Latn` |
| `sv` | Su√©dois | `swe_Latn` |
| `no` | Norv√©gien | `nob_Latn` |
| `da` | Danois | `dan_Latn` |
| `fi` | Finnois | `fin_Latn` |
| `el` | Grec | `ell_Grek` |

Liste compl√®te : https://github.com/facebookresearch/flores/blob/main/flores200/README.md#languages-in-flores-200

## ‚öôÔ∏è Configuration avanc√©e

### Taille du mod√®le

Trois mod√®les disponibles :

| Taille | RAM | Vitesse | Qualit√© | Recommand√© pour |
|--------|-----|---------|---------|-----------------|
| 600M | ~2GB | ‚ö°‚ö°‚ö° Rapide | ‚≠ê‚≠ê‚≠ê‚≠ê Tr√®s bonne | **Production** |
| 1.3B | ~5GB | ‚ö°‚ö° Moyen | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellente | Serveurs puissants |
| 3.3B | ~13GB | ‚ö° Lent | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Exceptionnelle | Recherche |

Configuration dans `.env` :
```bash
AI_NLLB_MODEL_SIZE=600M  # ou 1.3B, 3.3B
```

### Batch size

Le script Python traite les textes par lots de 8. Modifier dans `translate_nllb.py` ligne 112 :

```python
batch_size = 8  # Ajuster selon RAM disponible
```

### GPU (optionnel)

Si CUDA/GPU disponible, le script l'utilise automatiquement. V√©rifier :

```bash
python3 -c "import torch; print('GPU:', torch.cuda.is_available())"
```

Si GPU disponible, la traduction sera **beaucoup plus rapide** (~10-50x).

## üîç Debugging

### Logs Laravel

```bash
tail -f storage/logs/laravel.log
```

Chercher :
- `Ex√©cution NLLB script` : D√©marrage traduction
- `NLLB JSON parse error` : Erreur parsing r√©ponse Python
- `NLLB translation failed` : Erreur mod√®le

### Logs Python

Le script affiche sur stderr :
```
Chargement du mod√®le facebook/nllb-200-distilled-600m...
Device set to use cpu
Mod√®le charg√© avec succ√®s (device: CPU)
```

### Erreurs communes

#### `NLLB script not found`

Le script `scripts/translate_nllb.py` est manquant ou non ex√©cutable.

Solution :
```bash
chmod +x scripts/translate_nllb.py
```

#### `Invalid JSON response`

Le script Python a √©chou√©. V√©rifier :
```bash
python3 scripts/translate_nllb.py --source en --target fr --text "Hello"
```

#### `ModuleNotFoundError: No module named 'transformers'`

D√©pendances manquantes.

Solution :
```bash
pip3 install -r scripts/requirements.txt
```

#### `torch.cuda.OutOfMemoryError`

GPU manque de m√©moire. Forcer CPU :

```bash
export CUDA_VISIBLE_DEVICES=""
```

## üìä Comparaison providers

| Provider | Gratuit | Langues | Qualit√© | Batch | API Key | Local |
|----------|---------|---------|---------|-------|---------|-------|
| **NLLB-200** | ‚úÖ Illimit√© | 200 | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ Natif | ‚ùå Non | ‚úÖ Oui |
| DeepL | ‚úÖ 500k/mois | 30 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ 50 texts | ‚úÖ Oui | ‚ùå Non |
| MyMemory | ‚úÖ 10k/jour | 100+ | ‚≠ê‚≠ê‚≠ê | ‚ùå Non | ‚ùå Non | ‚ùå Non |
| LibreTranslate | ‚ö†Ô∏è Limit√© | 50+ | ‚≠ê‚≠ê‚≠ê | ‚ùå Non | ‚úÖ Oui | ‚ö†Ô∏è Possible |

### Recommandations

- **Langues europ√©ennes** : DeepL (si source support√©e) > NLLB-200 > MyMemory
- **Langues asiatiques** : **NLLB-200** > MyMemory (DeepL non support√©)
- **Volume √©lev√©** : **NLLB-200** (illimit√©) > DeepL (500k/mois) > MyMemory (10k/jour)
- **Confidentialit√©** : **NLLB-200** (local) > Autres (cloud)
- **Qualit√© maximale** : DeepL > NLLB-200 > LibreTranslate > MyMemory

## üöÄ Performance

### Benchmark projet 27 timecodes (chinois ‚Üí fran√ßais)

| Provider | Mode | Temps | Qualit√© | Notes |
|----------|------|-------|---------|-------|
| **NLLB-200 600M** | Batch | **~15s** | ‚≠ê‚≠ê‚≠ê‚≠ê | 3-5s startup + 12s traduction |
| DeepL | Fallback MyMemory | ~35s | ‚≠ê‚≠ê‚≠ê | Source zh non support√© |
| MyMemory | Phrase-by-phrase | ~40s | ‚≠ê‚≠ê‚≠ê | 100ms d√©lai entre phrases |

## üìö Ressources

- **Mod√®le** : https://huggingface.co/facebook/nllb-200-distilled-600m
- **Paper** : https://arxiv.org/abs/2207.04672
- **FLORES-200** : https://github.com/facebookresearch/flores
- **Transformers** : https://huggingface.co/docs/transformers

## üêõ Troubleshooting

### Le mod√®le prend du temps √† t√©l√©charger

Le premier lancement t√©l√©charge ~2GB depuis Hugging Face. Ensuite, le mod√®le est cach√© dans `~/.cache/huggingface/`.

### Traduction de mauvaise qualit√©

- V√©rifier la langue source d√©tect√©e dans les logs
- Augmenter le mod√®le : `AI_NLLB_MODEL_SIZE=1.3B`
- Activer le contexte personnages : `AI_TRANSLATION_USE_CONTEXT=true`

### Worker Laravel bloqu√©

Le worker attend la fin du script Python (~15s pour 27 timecodes). C'est normal.

Logs :
```
[processing] Traduction batch avec NLLB-200...
[processing] 10/27 timecodes traduits...
[completed] Traduction termin√©e !
```

---

**Derni√®re mise √† jour** : 31 octobre 2025  
**Version** : 1.0.0  
**Maintainer** : Martin P. (@ParizetM)
